{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f09fc4d6-abe1-434b-97aa-ab7135ffed9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "lWhkG5r5ITPl"
   },
   "source": [
    "# Module 02 - Reading & Writing Data - Exercises## InstructionsThis notebook contains exercises based on the concepts learned in Module 02.- Complete each exercise in the provided code cells- Run the data setup cells first to generate/create necessary data- Test your solutions by running the verification cells (if provided)- Refer back to the main module notebook if you need help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60fbe903-1dca-4226-9ba1-b733293e93cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "b_M5kf7CITPm"
   },
   "source": [
    "## Data Setup\n",
    "\n",
    "Run the cells below to set up the data needed for the exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3204337a-7eee-4108-84a8-24b6a2010c4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sA4dnjMGITPm",
    "outputId": "56bdb27b-3099-4e2e-9a4c-5fd86a9a3bb1"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType,\n",
    "    IntegerType, DoubleType, DateType\n",
    ")\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(f\"Module 1 Exercises\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set data directory\n",
    "data_dir = \"../data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "print(\"SparkSession created successfully!\")\n",
    "print(f\"Data directory: {os.path.abspath(data_dir)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Generate sample CSV data\n",
    "# -----------------------------\n",
    "csv_data = {\n",
    "    \"id\": range(1, 1001),\n",
    "    \"name\": [f\"Person_{i}\" for i in range(1, 1001)],\n",
    "    \"age\": np.random.randint(20, 60, 1000),\n",
    "    \"city\": np.random.choice(\n",
    "        [\"NYC\", \"LA\", \"Chicago\", \"Houston\", \"Phoenix\"], 1000\n",
    "    ),\n",
    "    \"salary\": np.random.randint(40000, 120000, 1000)\n",
    "}\n",
    "\n",
    "df_csv = pd.DataFrame(csv_data)\n",
    "df_csv.to_csv(f\"{data_dir}/exercise_data.csv\", index=False)\n",
    "\n",
    "print(f\"Created CSV file: {data_dir}/exercise_data.csv\")\n",
    "\n",
    "# -----------------------------\n",
    "# Generate sample JSON data\n",
    "# -----------------------------\n",
    "json_data = [\n",
    "    {\n",
    "        \"id\": i,\n",
    "        \"product\": f\"Product_{i}\",\n",
    "        \"price\": round(np.random.uniform(10, 100), 2),\n",
    "        \"category\": np.random.choice(\n",
    "            [\"Electronics\", \"Clothing\", \"Food\", \"Books\"], 1\n",
    "        )[0]\n",
    "    }\n",
    "    for i in range(1, 501)\n",
    "]\n",
    "\n",
    "with open(f\"{data_dir}/exercise_data.json\", \"w\") as f:\n",
    "    json.dump(json_data, f, indent=2)\n",
    "\n",
    "print(f\"Created JSON file: {data_dir}/exercise_data.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fedcdda-1a31-4d8f-851f-1154d5008f8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xiezMlR4ITPn"
   },
   "source": [
    "## ExercisesComplete the following exercises based on the concepts from Module 02."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdbde351-cfc8-411d-b85d-1b7419764967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H0oJo-nuITPn"
   },
   "source": [
    "### Exercise 1: Read CSV FileRead the 'exercise_data.csv' file from the data directory and display the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5980403e-36ad-45f5-a5d2-128ba16ef280",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nLJYhDxpITPo",
    "outputId": "1c42f4f4-c1f5-4cd0-f857-881e9913336c"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_1 = spark.read.csv(f\"{data_dir}/exercise_data.csv\",header=True)\n",
    "df_1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dc174ac-5ae7-4c51-8c5d-a17f67d09eab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "kIvVDfSsITPo"
   },
   "source": [
    "### Exercise 2: Read JSON FileRead the 'exercise_data.json' file from the data directory and display the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28219a4e-f9a5-432c-b686-2b60ebe8e743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OyXlYmnVITPo",
    "outputId": "e15e8d81-29ee-4533-8d6b-cd54032d47b2"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_2 = spark.read \\\n",
    "        .format('json') \\\n",
    "        .option('multiline',True) \\\n",
    "        .load(f\"{data_dir}/exercise_data.json\")\n",
    "\n",
    "df_2.show()\n",
    "df_2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8c64936-b6c3-4249-98da-5db83d1c41b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1TPpUGHLITPo"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "### Exercise 3: Write to ParquetWrite the DataFrame from Exercise 1 to a Parquet file named 'output_exercise.parquet' in the data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92f09393-e517-4db6-be27-001385378cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hidllK_GITPo",
    "outputId": "0e6fc186-3db3-4512-f57d-2ebe8c5c973f"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "df_1.printSchema()\n",
    "df_1.write.parquet(f\"{data_dir}/output_exercise.parquet\",mode=\"overwrite\")\n",
    "df_1.show()\n",
    "df_1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e04a079-3400-43b5-8281-67da65614191",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H5GUxOoLITPo"
   },
   "source": [
    "## Summary\n",
    "\n",
    "Great job completing the exercises! Review your solutions and compare them with the solutions notebook if needed.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "02_reading_writing_data_exercises",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
